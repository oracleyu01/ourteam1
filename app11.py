import cv2
import tempfile
import streamlit as st
from ultralytics import YOLO
from PIL import Image
import ffmpeg
import shutil
from io import BytesIO

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Sophisticated Batting Swing Detection", page_icon="ğŸ¨")

# ìŠ¤íƒ€ì¼ë§ íƒ€ì´í‹€
st.markdown(
    "<h1 style='text-align: center; color: #D2691E;'>Sophisticated Batting Swing Detection</h1>",
    unsafe_allow_html=True,
)
st.markdown(
    "<h3 style='text-align: center; color: #8B4513;'>Analyze batting swings with ease ğŸ¬</h3>",
    unsafe_allow_html=True,
)

# ëª¨ë‚˜ë¦¬ì ì´ë¯¸ì§€ í‘œì‹œ
st.markdown("<h4 style='text-align: center;'>Sample Artwork</h4>", unsafe_allow_html=True)
try:
    monalisa_image = Image.open("monariza.png")  # ëª¨ë‚˜ë¦¬ì ì´ë¯¸ì§€ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”
    st.image(monalisa_image, caption="Mona Lisa (by Leonardo da Vinci)", use_column_width=True)
except FileNotFoundError:
    st.error("ëª¨ë‚˜ë¦¬ì ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# YOLO ëª¨ë¸ ë¡œë“œ
model = YOLO('hitter_trained_model.pt')

# í´ë˜ìŠ¤ ì´ë¦„ ì„¤ì •
class_names = ["geonchang", "other_class"]

# Sidebar ì„¤ì •
st.sidebar.header("Settings âš™ï¸")
confidence_threshold = st.sidebar.slider("Confidence Threshold", 0.1, 1.0, 0.6, 0.05)

# íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ë™ì˜ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["mp4", "avi", "mov"])
if uploaded_file is not None:
    st.sidebar.success("íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")

    # ì„ì‹œ íŒŒì¼ì— ì—…ë¡œë“œëœ ë™ì˜ìƒì„ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as temp_video:
        shutil.copyfileobj(uploaded_file, temp_video)
        temp_video_path = temp_video.name

    # ë™ì˜ìƒ ë¡œë“œ
    cap = cv2.VideoCapture(temp_video_path)
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)

    # ê²°ê³¼ ë™ì˜ìƒ ì €ì¥
    output_temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_temp_file.name, fourcc, fps, (frame_width, frame_height))

    st.write("ğŸ”„ **Processing video, please wait...**")
    
    # í”„ë ˆì„ë§ˆë‹¤ YOLO ê²€ì¶œ ìˆ˜í–‰
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # ëª¨ë¸ë¡œ ì‚¬ë¬¼ ê²€ì¶œ ìˆ˜í–‰
        results = model(frame)

        for result in results:
            boxes = result.boxes  # ê²€ì¶œëœ ë°•ìŠ¤ë“¤
            for box in boxes:
                if box.conf >= confidence_threshold:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    confidence = box.conf.item()
                    class_id = int(box.cls.item())
                    label = f"{class_names[class_id]} {confidence:.2f}"
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
                    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

        out.write(frame)

    # ë¦¬ì†ŒìŠ¤ í•´ì œ
    cap.release()
    out.release()

    # ffmpegë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ íŒŒì¼ì„ ë‹¤ì‹œ ì¸ì½”ë”©
    encoded_temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    ffmpeg.input(output_temp_file.name).output(encoded_temp_file.name, codec='libx264', pix_fmt='yuv420p').run(overwrite_output=True)
    
    # Streamlitì— ê²°ê³¼ ë™ì˜ìƒ í‘œì‹œ
    with open(encoded_temp_file.name, 'rb') as f:
        video_bytes = f.read()
    st.video(BytesIO(video_bytes))

    # ì™„ë£Œ ë©”ì‹œì§€
    st.success("ğŸ‰ ê²€ì¶œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!") 
