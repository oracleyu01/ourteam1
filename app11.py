import streamlit as st
import tempfile
import cv2
from ultralytics import YOLO
from PIL import Image
from moviepy.editor import VideoFileClip

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Sophisticated Batting Swing Detection", page_icon="ğŸ¨")

# ìŠ¤íƒ€ì¼ë§ íƒ€ì´í‹€
st.markdown(
    "<h1 style='text-align: center; color: #D2691E;'>Sophisticated Batting Swing Detection</h1>",
    unsafe_allow_html=True,
)
st.markdown(
    "<h3 style='text-align: center; color: #8B4513;'>Analyze batting swings with ease ğŸ¬</h3>",
    unsafe_allow_html=True,
)

# ëª¨ë‚˜ë¦¬ì ì´ë¯¸ì§€ í‘œì‹œ
st.markdown("<h4 style='text-align: center;'>Sample Artwork</h4>", unsafe_allow_html=True)
monalisa_image = Image.open("monariza.png")  # ëª¨ë‚˜ë¦¬ì ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”
st.image(monalisa_image, caption="Mona Lisa (by Leonardo da Vinci)", use_column_width=True)

# ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
@st.cache_resource
def load_model():
    try:
        model = YOLO('hitter_trained_model.pt')  # ëª¨ë¸ íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”
        return model
    except Exception as e:
        st.error(f"Error loading model: {e}")
        return None

model = load_model()
if model is None:
    st.stop()  # ëª¨ë¸ì´ ì—†ìœ¼ë©´ ì•± ì¤‘ì§€

# í´ë˜ìŠ¤ ì´ë¦„ ì„¤ì •
class_names = ["geonchang", "other_class"]  # ìˆ˜ì • ê°€ëŠ¥í•œ í´ë˜ìŠ¤ ì´ë¦„

# Sidebar ì„¤ì •
st.sidebar.header("Settings âš™ï¸")
confidence_threshold = st.sidebar.slider("Confidence Threshold", 0.1, 1.0, 0.6, 0.05)

# íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ë™ì˜ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["mp4", "avi", "mov"])
if uploaded_file is not None:
    st.sidebar.success("íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")

    # ì„ì‹œ íŒŒì¼ì— ì—…ë¡œë“œëœ ë™ì˜ìƒì„ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as temp_video:
        temp_video.write(uploaded_file.read())
        temp_video_path = temp_video.name

    # ë™ì˜ìƒ ë¡œë“œ
    cap = cv2.VideoCapture(temp_video_path)
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)

    # ê²°ê³¼ ë™ì˜ìƒ ì €ì¥
    output_temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_temp_file.name, fourcc, fps, (frame_width, frame_height))

    st.write("ğŸ”„ **Processing video, please wait...**")
    
    # í”„ë ˆì„ë§ˆë‹¤ YOLO ê²€ì¶œ ìˆ˜í–‰
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # ëª¨ë¸ë¡œ ì‚¬ë¬¼ ê²€ì¶œ ìˆ˜í–‰
        results = model(frame)

        for result in results:
            boxes = result.boxes  # ê²€ì¶œëœ ë°•ìŠ¤ë“¤
            for box in boxes:
                if box.conf >= confidence_threshold:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    confidence = box.conf.item()
                    class_id = int(box.cls.item())
                    label = f"{class_names[class_id]} {confidence:.2f}"
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
                    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

        out.write(frame)

    # ë¦¬ì†ŒìŠ¤ í•´ì œ
    cap.release()
    out.release()

    # MoviePyë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì˜ìƒì„ ì›¹ í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    output_clip = VideoFileClip(output_temp_file.name)
    output_clip.write_videofile(output_temp_file.name, codec="libx264")

    # Streamlitì— ê²°ê³¼ ë™ì˜ìƒ í‘œì‹œ
    st.video(output_temp_file.name)

    # ì™„ë£Œ ë©”ì‹œì§€
    st.success("ğŸ‰ ê²€ì¶œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
else:
    st.write("ë™ì˜ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
